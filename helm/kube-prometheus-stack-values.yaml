## 独立安装 Grafana
grafana:
  enabled: false

# name: prometheus-server # Prometheus server container name
# fullnameOverride: prometheus-server

prometheus:
  service:
    enabled: true
    type: LoadBalancer # NodePort, ClusterIP
    annotations:
      service.beta.kubernetes.io/aws-load-balancer-type: "external" # use lbc
      service.beta.kubernetes.io/aws-load-balancer-nlb-target-type: ip
      service.beta.kubernetes.io/aws-load-balancer-scheme: internet-facing # only for test    
  prometheusSpec:
    nodeSelector:
      role: system
    scrapeInterval: "30s" # Defaults to 30s
    scrapeTimeout: "10s" # Number of seconds to wait for target to respond before erroring
    evaluationInterval: "1m" # Interval between consecutive evaluations.
    image:
      registry: quay.io
      repository: prometheus/prometheus
    ## If true, a nil or {} value for prometheus.prometheusSpec.serviceMonitorSelector will cause the
    ## prometheus resource to be created with selectors based on values in the helm deployment,
    ## which will also match the servicemonitors created
    serviceMonitorSelectorNilUsesHelmValues: true
    retention: "15d" # How long to retain metrics
    storageSpec:
    ## Using PersistentVolumeClaim 
    ## https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    ## TODO subPath?
      volumeClaimTemplate:
        spec:
          selector:
            matchLabels:
              otel.pv/name: ${EFS_PV_OTEL}
          resources:
            requests:
              storage: 300Gi
    ## AdditionalScrapeConfigs allows specifying additional Prometheus scrape configurations. Scrape configurations
    ## are appended to the configurations generated by the Prometheus Operator. Job configurations must have the form
    ## as specified in the official Prometheus documentation:
    ## https://prometheus.io/docs/prometheus/latest/configuration/configuration/#scrape_config. As scrape configs are
    ## appended, the user is responsible to make sure it is valid. Note that using this feature may expose the possibility
    ## to break upgrades of Prometheus. It is advised to review Prometheus release notes to ensure that no incompatible
    ## scrape configs are going to break Prometheus after the upgrade.
    ## AdditionalScrapeConfigs can be defined as a list or as a templated string.
    ##
    ## The scrape configuration example below will find master nodes, provided they have the name .*mst.*, relabel the
    ## port to 2379 and allow etcd scraping provided it is running on all Kubernetes master nodes
    additionalScrapeConfigs: |
    - job_name: karpenter
      kubernetes_sd_configs:
      - role: endpoints
        namespaces:
          names:
          - karpenter
      relabel_configs:
      - source_labels: [__meta_kubernetes_endpoint_port_name]
        regex: http-metrics
        action: keep

alertmanager:
  enabled: true
  alertmanagerSpec:
    nodeSelector:
      role: system
    ## ref: https://github.com/prometheus-operator/prometheus-operator/blob/main/Documentation/user-guides/storage.md
    storage:
      volumeClaimTemplate:
        spec:
          storageClassName: gp3
          accessModes: ["ReadWriteOnce"]
          resources:
            requests:
              storage: 10Gi
